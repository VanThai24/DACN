# HÆ¯á»šNG DáºªN TRAIN AI VÃ€ TÃCH Há»¢P VÃ€O DESKTOP APP

## ğŸ“‹ Má»¥c Lá»¥c
1. [Tá»•ng Quan](#tá»•ng-quan)
2. [Chuáº©n Bá»‹ Dá»¯ Liá»‡u](#chuáº©n-bá»‹-dá»¯-liá»‡u)
3. [Training Model](#training-model)
4. [ÄÃ¡nh GiÃ¡ Model](#Ä‘Ã¡nh-giÃ¡-model)
5. [Export Model cho Desktop](#export-model-cho-desktop)
6. [TÃ­ch Há»£p vÃ o Desktop App](#tÃ­ch-há»£p-vÃ o-desktop-app)
7. [Troubleshooting](#troubleshooting)

---

## ğŸ¯ Tá»•ng Quan

Quy trÃ¬nh train AI vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao nháº¥t:

```
Chuáº©n bá»‹ dá»¯ liá»‡u â†’ Train Model â†’ ÄÃ¡nh giÃ¡ â†’ Export â†’ TÃ­ch há»£p Desktop
```

### Má»¥c TiÃªu
- **Accuracy â‰¥ 95%** trÃªn validation set
- **Fast inference** cho real-time detection
- **Robust** vá»›i lighting, angle variations
- **Small model size** cho desktop deployment

---

## ğŸ“ Chuáº©n Bá»‹ Dá»¯ Liá»‡u

### 1. Cáº¥u TrÃºc ThÆ° Má»¥c

```
DACN/AI/face_data/
â”œâ”€â”€ Huy/
â”‚   â”œâ”€â”€ 001.jpg
â”‚   â”œâ”€â”€ 002.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ Thai/
â”‚   â”œâ”€â”€ 001.jpg
â”‚   â”œâ”€â”€ 002.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ Phong/
â”‚   â””â”€â”€ ...
â””â”€â”€ ...
```

### 2. YÃªu Cáº§u Dá»¯ Liá»‡u

**Sá»‘ lÆ°á»£ng:**
- **Tá»‘i thiá»ƒu**: 10-15 áº£nh/ngÆ°á»i
- **Khuyáº¿n nghá»‹**: 20-30 áº£nh/ngÆ°á»i
- **Tá»‘i Æ°u**: 50+ áº£nh/ngÆ°á»i

**Cháº¥t lÆ°á»£ng:**
- âœ… KhuÃ´n máº·t rÃµ rÃ ng, khÃ´ng bá»‹ che
- âœ… Äá»§ Ã¡nh sÃ¡ng
- âœ… GÃ³c chá»¥p Ä‘a dáº¡ng (tháº³ng, nghiÃªng trÃ¡i/pháº£i)
- âœ… Biá»ƒu cáº£m khÃ¡c nhau
- âœ… Äá»™ phÃ¢n giáº£i â‰¥ 160x160 px
- âŒ KhÃ´ng má», khÃ´ng tá»‘i
- âŒ KhÃ´ng cÃ³ nhiá»u ngÆ°á»i trong 1 áº£nh

### 3. Thu Tháº­p Dá»¯ Liá»‡u

**CÃ¡ch 1: Chá»¥p tá»« webcam**
```python
import cv2
import os

name = "Ten_Nguoi"
save_dir = f"face_data/{name}"
os.makedirs(save_dir, exist_ok=True)

cap = cv2.VideoCapture(0)
count = 0

while count < 30:  # Chá»¥p 30 áº£nh
    ret, frame = cap.read()
    if ret:
        cv2.imshow('Press SPACE to capture', frame)
        key = cv2.waitKey(1)
        
        if key == ord(' '):  # Nháº¥n SPACE Ä‘á»ƒ chá»¥p
            cv2.imwrite(f"{save_dir}/{count:03d}.jpg", frame)
            print(f"Captured {count+1}/30")
            count += 1
        elif key == ord('q'):  # Nháº¥n Q Ä‘á»ƒ thoÃ¡t
            break

cap.release()
cv2.destroyAllWindows()
```

**CÃ¡ch 2: Tá»« video**
```python
import cv2
import os

video_path = "video_person.mp4"
name = "Ten_Nguoi"
save_dir = f"face_data/{name}"
os.makedirs(save_dir, exist_ok=True)

cap = cv2.VideoCapture(video_path)
count = 0
frame_skip = 10  # Láº¥y 1 frame má»—i 10 frames

while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    if count % frame_skip == 0:
        cv2.imwrite(f"{save_dir}/{count//frame_skip:03d}.jpg", frame)
    
    count += 1

cap.release()
print(f"Extracted {count//frame_skip} images")
```

### 4. Kiá»ƒm Tra Dá»¯ Liá»‡u

```python
import os

data_dir = "face_data"
for person in os.listdir(data_dir):
    person_dir = os.path.join(data_dir, person)
    if os.path.isdir(person_dir):
        num_images = len([f for f in os.listdir(person_dir) 
                         if f.endswith(('.jpg', '.jpeg', '.png'))])
        print(f"{person}: {num_images} áº£nh")
```

---

## ğŸš€ Training Model

### 1. CÃ i Äáº·t Dependencies

```powershell
cd DACN\AI
pip install tensorflow==2.15.0
pip install numpy opencv-python matplotlib seaborn scikit-learn
pip install pillow
```

### 2. Cháº¡y Training

```powershell
cd DACN\AI
python train_ai_optimized.py
```

### 3. QuÃ¡ TrÃ¬nh Training

**Phase 1: Train vá»›i Base Model Frozen (30 epochs)**
- Base model (MobileNetV2) bá»‹ frozen
- Chá»‰ train Dense layers + Embedding layer
- Learning rate: 0.0001

**Phase 2: Fine-tuning (70 epochs)**
- Unfreeze 50% cuá»‘i base model
- Train toÃ n bá»™ model
- Learning rate: 0.00001 (tháº¥p hÆ¡n 10 láº§n)

### 4. Callbacks & Optimizations

- **Early Stopping**: Dá»«ng khi val_accuracy khÃ´ng cáº£i thiá»‡n sau 15 epochs
- **Learning Rate Reduction**: Giáº£m LR xuá»‘ng 50% khi val_loss plateau (5 epochs)
- **Model Checkpoint**: LÆ°u best model theo val_accuracy
- **TensorBoard**: Log training metrics

### 5. Theo DÃµi Training

**Option 1: Console output**
```
Epoch 1/100
45/45 [==============================] - 25s 550ms/step - loss: 2.1234 - accuracy: 0.8567 - val_loss: 1.5432 - val_accuracy: 0.9012
```

**Option 2: TensorBoard**
```powershell
tensorboard --logdir=DACN\AI\logs
```
Má»Ÿ browser: http://localhost:6006

### 6. Output Files

Sau khi training xong:
```
DACN/AI/
â”œâ”€â”€ faceid_optimized_model.h5        # Model cuá»‘i cÃ¹ng
â”œâ”€â”€ faceid_optimized_best.h5         # Best model (theo val_accuracy)
â”œâ”€â”€ training_history.png              # Biá»ƒu Ä‘á»“ training
â”œâ”€â”€ class_mapping.json                # Mapping class index -> name
â””â”€â”€ logs/                             # TensorBoard logs
```

---

## ğŸ“Š ÄÃ¡nh GiÃ¡ Model

### 1. Cháº¡y Evaluation

```powershell
cd DACN\AI
python evaluate_model_accuracy.py
```

### 2. Metrics

Script sáº½ tÃ­nh toÃ¡n:
- **Overall Accuracy**: Äá»™ chÃ­nh xÃ¡c tá»•ng thá»ƒ
- **Precision**: Tá»· lá»‡ dá»± Ä‘oÃ¡n Ä‘Ãºng trong cÃ¡c dá»± Ä‘oÃ¡n positive
- **Recall**: Tá»· lá»‡ phÃ¡t hiá»‡n Ä‘Ãºng trong cÃ¡c máº«u positive thá»±c táº¿
- **F1-Score**: Trung bÃ¬nh Ä‘iá»u hÃ²a cá»§a Precision vÃ  Recall
- **Confusion Matrix**: Ma tráº­n nháº§m láº«n
- **Per-Class Metrics**: Metrics cho tá»«ng ngÆ°á»i

### 3. Äá»c Káº¿t Quáº£

```
================================================================================
Káº¾T QUáº¢ Tá»”NG QUÃT
================================================================================
Overall Accuracy:  96.50%
Weighted Precision: 96.75%
Weighted Recall:    96.50%
Weighted F1-Score:  96.55%
================================================================================
```

**ÄÃ¡nh giÃ¡:**
- âœ… **Excellent**: Accuracy â‰¥ 95%
- âœ… **Good**: Accuracy â‰¥ 90%
- âš ï¸ **Fair**: Accuracy â‰¥ 85%
- âŒ **Poor**: Accuracy < 85%

### 4. PhÃ¢n TÃ­ch Lá»—i

Script sáº½ hiá»ƒn thá»‹:
- Sá»‘ máº«u bá»‹ phÃ¢n loáº¡i sai
- Top 10 lá»—i phá»• biáº¿n nháº¥t
- Confidence distribution (Ä‘Ãºng vs sai)

**VÃ­ dá»¥:**
```
Má»™t sá»‘ vÃ­ dá»¥ phÃ¢n loáº¡i sai:
  1. Sample 45: True='Thai' â†’ Predicted='Huy' (confidence: 78.23%)
  2. Sample 67: True='Phong' â†’ Predicted='Quang' (confidence: 65.44%)
```

### 5. Output Files

```
DACN/AI/
â”œâ”€â”€ confusion_matrix.png           # Ma tráº­n nháº§m láº«n
â”œâ”€â”€ per_class_metrics.png          # Metrics tá»«ng ngÆ°á»i
â”œâ”€â”€ confidence_distribution.png    # PhÃ¢n bá»‘ confidence
â””â”€â”€ evaluation_results.json        # Káº¿t quáº£ chi tiáº¿t (JSON)
```

---

## ğŸ“¦ Export Model cho Desktop

### 1. Cháº¡y Export Script

```powershell
cd DACN\AI
python export_embedding_model.py
```

### 2. Output Files

```
DACN/AI/
â”œâ”€â”€ faceid_embedding_model.h5      # Embedding model (.h5)
â”œâ”€â”€ faceid_embedding_savedmodel/   # SavedModel format
â””â”€â”€ faceid_inference.py            # Helper class
```

### 3. Embedding Model vs Full Model

**Full Model:**
```
Input (160x160x3) â†’ CNN â†’ Embedding (128) â†’ Classification (N classes)
```

**Embedding Model:**
```
Input (160x160x3) â†’ CNN â†’ Embedding (128)
```

Embedding model chá»‰ output vector 128-dim (L2 normalized), dÃ¹ng Ä‘á»ƒ:
- So sÃ¡nh similarity giá»¯a 2 faces
- TÃ¬m kiáº¿m face trong database
- Real-time face verification

---

## ğŸ–¥ï¸ TÃ­ch Há»£p vÃ o Desktop App

### 1. Copy Files

```powershell
# Copy model
Copy-Item "DACN\AI\faceid_embedding_model.h5" -Destination "DACN\faceid_desktop\"

# Copy helper
Copy-Item "DACN\AI\faceid_inference.py" -Destination "DACN\faceid_desktop\"

# Copy class mapping (optional)
Copy-Item "DACN\AI\class_mapping.json" -Destination "DACN\faceid_desktop\"
```

### 2. Update Desktop App

**File: `DACN\faceid_desktop\main.py`**

```python
import cv2
import numpy as np
import requests
from faceid_inference import FaceIDEmbedding

class FaceIDApp(QWidget):
    def __init__(self):
        super().__init__()
        
        # Load embedding model
        model_path = os.path.join(os.path.dirname(__file__), 
                                  "faceid_embedding_model.h5")
        self.face_model = FaceIDEmbedding(model_path)
        
        # API endpoint
        self.api_url = "http://localhost:5000"
        
    def recognize_face(self, frame):
        """Nháº­n diá»‡n khuÃ´n máº·t tá»« frame"""
        
        # Extract embedding
        embedding = self.face_model.extract_embedding(frame)
        
        # Gá»­i lÃªn server Ä‘á»ƒ match
        response = requests.post(
            f"{self.api_url}/recognize",
            json={
                "embedding": embedding.tolist()
            }
        )
        
        if response.status_code == 200:
            result = response.json()
            return result['name'], result['similarity']
        
        return None, 0.0
    
    def scan_face(self):
        """QuÃ©t khuÃ´n máº·t tá»« camera"""
        cap = cv2.VideoCapture(0)
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # Recognize
            name, similarity = self.recognize_face(frame)
            
            if name and similarity > 0.6:  # Threshold
                print(f"Nháº­n diá»‡n: {name} (similarity: {similarity:.2f})")
                # TODO: Cáº­p nháº­t UI, ghi log, etc.
            
            # Display
            cv2.imshow('Face Scan', frame)
            
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        cap.release()
        cv2.destroyAllWindows()
```

### 3. Sá»­ Dá»¥ng Embedding

**So sÃ¡nh 2 faces:**
```python
# Extract embeddings
emb1 = face_model.extract_embedding(image1)
emb2 = face_model.extract_embedding(image2)

# Cosine similarity
similarity = face_model.cosine_similarity(emb1, emb2)
print(f"Similarity: {similarity:.4f}")

# Check if same person
is_same, score = face_model.is_same_person(emb1, emb2, threshold=0.6)
if is_same:
    print("Same person!")
else:
    print("Different person!")
```

**TÃ¬m kiáº¿m trong database:**
```python
# Load embeddings tá»« database
database_embeddings = load_embeddings_from_db()

# Extract embedding tá»« query image
query_embedding = face_model.extract_embedding(query_image)

# Find best match
best_match = None
best_similarity = 0.0

for person_id, db_embedding in database_embeddings.items():
    similarity = face_model.cosine_similarity(query_embedding, db_embedding)
    if similarity > best_similarity:
        best_similarity = similarity
        best_match = person_id

if best_similarity > 0.6:  # Threshold
    print(f"Matched: {best_match} (similarity: {best_similarity:.2f})")
else:
    print("No match found")
```

### 4. Threshold Tuning

**Recommended thresholds:**
- **Strict** (High security): 0.7 - 0.8
- **Balanced**: 0.6 - 0.7
- **Loose** (High recall): 0.5 - 0.6

Tune threshold dá»±a trÃªn:
- False Positive Rate (FPR): NgÆ°á»i láº¡ bá»‹ nháº­n diá»‡n nháº§m
- False Negative Rate (FNR): NgÆ°á»i Ä‘Ãºng bá»‹ tá»« chá»‘i

---

## ğŸ”§ Troubleshooting

### 1. Training Issues

**Problem: Loss khÃ´ng giáº£m**
```
Solutions:
- Giáº£m learning rate
- TÄƒng batch size
- Kiá»ƒm tra dá»¯ liá»‡u (cÃ³ bá»‹ lá»—i khÃ´ng?)
- Thá»­ architecture khÃ¡c
```

**Problem: Overfitting (val_loss tÄƒng)**
```
Solutions:
- TÄƒng dropout rate
- ThÃªm data augmentation
- ThÃªm L2 regularization
- Thu tháº­p thÃªm data
```

**Problem: Underfitting (accuracy tháº¥p)**
```
Solutions:
- TÄƒng model capacity (thÃªm layers)
- Train lÃ¢u hÆ¡n
- Giáº£m regularization
- Kiá»ƒm tra data quality
```

### 2. Data Issues

**Problem: KhÃ´ng Ä‘á»§ dá»¯ liá»‡u**
```
Solutions:
- Data augmentation máº¡nh hÆ¡n
- Thu tháº­p thÃªm tá»« video
- Synthesize data (GAN, morphing)
```

**Problem: Imbalanced classes**
```
Solutions:
- Oversample minority classes
- Undersample majority classes
- Class weights trong loss function
- SMOTE (Synthetic Minority Over-sampling)
```

### 3. Inference Issues

**Problem: Inference cháº­m**
```
Solutions:
- Quantization (TFLite, ONNX)
- Model pruning
- Use smaller model
- Batch processing
- GPU acceleration
```

**Problem: Accuracy tháº¥p trÃªn real data**
```
Solutions:
- Retrain vá»›i real data
- Fine-tune vá»›i real data
- Adjust threshold
- Improve preprocessing
```

### 4. Integration Issues

**Problem: Model khÃ´ng load Ä‘Æ°á»£c**
```python
# ThÃªm custom_objects khi load
model = tf.keras.models.load_model(
    model_path,
    custom_objects={'l2_normalize_func': l2_normalize_func}
)
```

**Problem: Embedding khÃ´ng consistent**
```python
# Äáº£m báº£o preprocessing giá»‘ng training
- Resize Ä‘Ãºng size (160x160)
- BGR â†’ RGB conversion
- Normalize [0, 255] â†’ [0, 1]
- ÄÃºng thá»© tá»± channels (RGB)
```

---

## ğŸ“ˆ Best Practices

### 1. Data Collection
- âœ… Collect diverse data (lighting, angles, expressions)
- âœ… Use high-quality images
- âœ… Balance classes (same number of images per person)
- âœ… Validate data quality before training

### 2. Training
- âœ… Use transfer learning (faster, better accuracy)
- âœ… Use data augmentation
- âœ… Monitor validation metrics
- âœ… Use callbacks (early stopping, LR reduction)
- âœ… Save best model, not final model

### 3. Evaluation
- âœ… Test on separate validation set
- âœ… Check confusion matrix
- âœ… Analyze misclassified samples
- âœ… Test with real-world data

### 4. Deployment
- âœ… Use embedding model (faster)
- âœ… Optimize inference (TFLite, ONNX)
- âœ… Set appropriate threshold
- âœ… Monitor performance in production
- âœ… Collect feedback for retraining

---

## ğŸ“š References

### Papers
- FaceNet: https://arxiv.org/abs/1503.03832
- MobileNetV2: https://arxiv.org/abs/1801.04381
- ArcFace: https://arxiv.org/abs/1801.07698

### Tutorials
- TensorFlow Face Recognition: https://www.tensorflow.org/tutorials
- Keras Transfer Learning: https://keras.io/guides/transfer_learning/

### Tools
- TensorBoard: https://www.tensorflow.org/tensorboard
- scikit-learn: https://scikit-learn.org/

---

## ğŸ¯ Quick Start

### Quy trÃ¬nh nhanh (5 bÆ°á»›c):

```powershell
# 1. Chuáº©n bá»‹ dá»¯ liá»‡u
# Táº¡o folder face_data vá»›i áº£nh cÃ¡c ngÆ°á»i

# 2. Train model
cd DACN\AI
python train_ai_optimized.py

# 3. ÄÃ¡nh giÃ¡
python evaluate_model_accuracy.py

# 4. Export embedding model
python export_embedding_model.py

# 5. Copy vÃ o desktop app
Copy-Item "faceid_embedding_model.h5" -Destination "..\faceid_desktop\"
Copy-Item "faceid_inference.py" -Destination "..\faceid_desktop\"
```

---

## ğŸ“ Support

Náº¿u gáº·p váº¥n Ä‘á», check:
1. Console output (error messages)
2. TensorBoard logs
3. Evaluation results
4. Data quality

---

**Happy Training! ğŸš€**
