"""
Script thu tháº­p áº£nh training cho Face Recognition
Chá»¥p 50 áº£nh tá»± Ä‘á»™ng vá»›i hÆ°á»›ng dáº«n thay Ä‘á»•i gÃ³c Ä‘á»™
"""

import cv2
import os
import time
from datetime import datetime

def capture_training_images(person_name, num_images=50):
    """
    Thu tháº­p áº£nh training cho má»™t ngÆ°á»i
    
    Args:
        person_name: TÃªn ngÆ°á»i (táº¡o folder vá»›i tÃªn nÃ y)
        num_images: Sá»‘ lÆ°á»£ng áº£nh cáº§n chá»¥p (máº·c Ä‘á»‹nh 50)
    """
    # Táº¡o thÆ° má»¥c náº¿u chÆ°a cÃ³
    save_dir = f"face_data/{person_name}"
    os.makedirs(save_dir, exist_ok=True)
    
    # Khá»Ÿi táº¡o webcam
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âŒ KhÃ´ng thá»ƒ má»Ÿ webcam!")
        return
    
    # Cáº¥u hÃ¬nh
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
    
    print(f"\n{'='*60}")
    print(f"ğŸ“¸ THU THáº¬P áº¢NH TRAINING CHO: {person_name}")
    print(f"{'='*60}")
    print(f"Sáº½ chá»¥p {num_images} áº£nh vá»›i cÃ¡c hÆ°á»›ng dáº«n:")
    print("  - 10 áº£nh: NhÃ¬n tháº³ng")
    print("  - 10 áº£nh: Xoay Ä‘áº§u trÃ¡i")
    print("  - 10 áº£nh: Xoay Ä‘áº§u pháº£i")
    print("  - 10 áº£nh: Ngáº©ng Ä‘áº§u lÃªn")
    print("  - 10 áº£nh: CÃºi Ä‘áº§u xuá»‘ng")
    print("\nâŒ¨ï¸  Nháº¥n SPACE Ä‘á»ƒ báº¯t Ä‘áº§u, ESC Ä‘á»ƒ thoÃ¡t")
    print(f"{'='*60}\n")
    
    # CÃ¡c hÆ°á»›ng dáº«n
    instructions = [
        ("ğŸ“· NhÃ¬n tháº³ng vÃ o camera", 10),
        ("â¬…ï¸ Xoay Ä‘áº§u sang TRÃI", 10),
        ("â¡ï¸ Xoay Ä‘áº§u sang PHáº¢I", 10),
        ("â¬†ï¸ Ngáº©ng Ä‘áº§u LÃŠN", 10),
        ("â¬‡ï¸ CÃºi Ä‘áº§u XUá»NG", 10)
    ]
    
    count = 0
    instruction_index = 0
    images_in_current_pose = 0
    started = False
    
    # Face detector
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    
    while count < num_images:
        ret, frame = cap.read()
        if not ret:
            print("âŒ KhÃ´ng Ä‘á»c Ä‘Æ°á»£c frame!")
            break
        
        # Láº­t áº£nh Ä‘á»ƒ dá»… nhÃ¬n
        frame = cv2.flip(frame, 1)
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # Detect faces
        faces = face_cascade.detectMultiScale(gray, 1.3, 5)
        
        # Váº½ khung vÃ  thÃ´ng tin
        for (x, y, w, h) in faces:
            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
            cv2.putText(frame, f"Face Detected", (x, y-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        
        # Hiá»ƒn thá»‹ hÆ°á»›ng dáº«n
        if instruction_index < len(instructions):
            instruction, target = instructions[instruction_index]
            status_text = f"{instruction} ({images_in_current_pose}/{target})"
        else:
            status_text = "HOÃ€N THÃ€NH!"
        
        # Overlay thÃ´ng tin
        overlay = frame.copy()
        cv2.rectangle(overlay, (0, 0), (frame.shape[1], 100), (0, 0, 0), -1)
        frame = cv2.addWeighted(overlay, 0.5, frame, 0.5, 0)
        
        cv2.putText(frame, status_text, (20, 35), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        cv2.putText(frame, f"Tong: {count}/{num_images}", (20, 70), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
        
        if not started:
            cv2.putText(frame, "Nhan SPACE de bat dau", (20, frame.shape[0]-20), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)
        
        cv2.imshow('Thu thap anh training - Nhan ESC de thoat', frame)
        
        key = cv2.waitKey(1) & 0xFF
        
        # Space Ä‘á»ƒ báº¯t Ä‘áº§u
        if key == ord(' '):
            if not started:
                started = True
                print("\nâ–¶ï¸  Báº¯t Ä‘áº§u chá»¥p áº£nh...")
            
            # Chá»¥p áº£nh náº¿u phÃ¡t hiá»‡n Ä‘Æ°á»£c máº·t
            if len(faces) > 0 and started:
                # Láº¥y khuÃ´n máº·t lá»›n nháº¥t
                x, y, w, h = max(faces, key=lambda face: face[2] * face[3])
                
                # Crop face vá»›i margin
                margin = 30
                y1 = max(0, y - margin)
                y2 = min(frame.shape[0], y + h + margin)
                x1 = max(0, x - margin)
                x2 = min(frame.shape[1], x + w + margin)
                face_img = frame[y1:y2, x1:x2]
                
                # LÆ°u áº£nh
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
                pose_name = instructions[instruction_index][0].split()[0]
                filename = f"{save_dir}/{pose_name}_{count+1:03d}_{timestamp}.jpg"
                cv2.imwrite(filename, face_img)
                
                count += 1
                images_in_current_pose += 1
                print(f"âœ… ÄÃ£ chá»¥p {count}/{num_images}: {filename}")
                
                # Chuyá»ƒn sang pose tiáº¿p theo
                if images_in_current_pose >= instructions[instruction_index][1]:
                    instruction_index += 1
                    images_in_current_pose = 0
                    if instruction_index < len(instructions):
                        print(f"\nğŸ”„ Chuyá»ƒn sang: {instructions[instruction_index][0]}")
                
                # Delay nhá» Ä‘á»ƒ trÃ¡nh chá»¥p quÃ¡ nhanh
                time.sleep(0.3)
        
        # ESC Ä‘á»ƒ thoÃ¡t
        elif key == 27:
            print("\nâš ï¸  ÄÃ£ há»§y bá»!")
            break
    
    cap.release()
    cv2.destroyAllWindows()
    
    if count >= num_images:
        print(f"\n{'='*60}")
        print(f"âœ… HOÃ€N THÃ€NH! ÄÃ£ chá»¥p {count} áº£nh cho {person_name}")
        print(f"ğŸ“ LÆ°u táº¡i: {save_dir}")
        print(f"{'='*60}\n")
        print("ğŸ”„ BÆ°á»›c tiáº¿p theo:")
        print("   1. Cháº¡y: python train_best_model.py")
        print("   2. Cháº¡y: python update_embeddings_best_model.py")
        print(f"{'='*60}\n")
    else:
        print(f"\nâš ï¸  Chá»‰ chá»¥p Ä‘Æ°á»£c {count}/{num_images} áº£nh")


def main():
    print("\n" + "="*60)
    print("ğŸ¯ CÃ”NG Cá»¤ THU THáº¬P Dá»® LIá»†U TRAINING FACE RECOGNITION")
    print("="*60)
    
    person_name = input("\nğŸ‘¤ Nháº­p tÃªn ngÆ°á»i (VD: Huy, Phong, Thai): ").strip()
    
    if not person_name:
        print("âŒ TÃªn khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng!")
        return
    
    try:
        num_images = int(input("ğŸ“¸ Sá»‘ lÆ°á»£ng áº£nh muá»‘n chá»¥p (khuyáº¿n nghá»‹ 50): ") or "50")
    except ValueError:
        num_images = 50
    
    if num_images < 20:
        print("âš ï¸  Khuyáº¿n nghá»‹ chá»¥p Ã­t nháº¥t 30-50 áº£nh Ä‘á»ƒ model chÃ­nh xÃ¡c hÆ¡n")
    
    confirm = input(f"\nâœ… Sáº½ chá»¥p {num_images} áº£nh cho {person_name}. Tiáº¿p tá»¥c? (y/n): ")
    
    if confirm.lower() == 'y':
        capture_training_images(person_name, num_images)
    else:
        print("âŒ ÄÃ£ há»§y!")


if __name__ == "__main__":
    main()
